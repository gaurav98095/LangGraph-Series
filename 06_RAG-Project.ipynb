{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebacbb1d",
   "metadata": {},
   "source": [
    "## RAG Project\n",
    "\n",
    "\n",
    "<img src=\"image-rag.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af222c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Create embeddings\n",
    "embedding_function = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example TechZone documents\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"TechZone is owned by Priya Sharma, a technology entrepreneur with over 15 years of experience in AI and cloud computing. She founded TechZone to make advanced technology accessible to businesses of all sizes.\",\n",
    "        metadata={\"source\": \"owner.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"TechZone offers a variety of subscription plans: Starter at ₹1,000/month, Professional at ₹5,000/month, and Enterprise custom plans starting from ₹20,000/month.\",\n",
    "        metadata={\"source\": \"pricing.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"TechZone's support hours are Monday to Friday, 9:00 AM to 8:00 PM IST, and Saturday from 10:00 AM to 4:00 PM IST. No support on Sundays.\",\n",
    "        metadata={\"source\": \"support_hours.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"TechZone provides multiple services including AI-powered analytics, cloud hosting, and API integrations for payment and customer management.\",\n",
    "        metadata={\"source\": \"services.txt\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store and retriever\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21002fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the following context and the Chat history.\n",
    "Especially take the latest question into consideration:\n",
    "\n",
    "Chat history: {history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Base LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db35f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent state definition\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    documents: List[Document]\n",
    "    on_topic: str\n",
    "    rephrased_question: str\n",
    "    proceed_to_generate: bool\n",
    "    rephrase_count: int\n",
    "    question: HumanMessage\n",
    "\n",
    "# Classifier output schema\n",
    "class GradeQuestion(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Is the question about specified TechZone topics? If yes -> 'Yes', otherwise -> 'No'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Question rewriter\n",
    "def question_rewriter(state: AgentState):\n",
    "    print(f\"Entering question_rewriter with state: {state}\")\n",
    "\n",
    "    # Reset\n",
    "    state[\"documents\"] = []\n",
    "    state[\"on_topic\"] = \"\"\n",
    "    state[\"rephrased_question\"] = \"\"\n",
    "    state[\"proceed_to_generate\"] = False\n",
    "    state[\"rephrase_count\"] = 0\n",
    "\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "\n",
    "    if state[\"question\"] not in state[\"messages\"]:\n",
    "        state[\"messages\"].append(state[\"question\"])\n",
    "\n",
    "    if len(state[\"messages\"]) > 1:\n",
    "        conversation = state[\"messages\"][:-1]\n",
    "        current_question = state[\"question\"].content\n",
    "        messages = [\n",
    "            SystemMessage(content=\"Rephrase the user's question so it is standalone and optimized for retrieval.\"),\n",
    "            *conversation,\n",
    "            HumanMessage(content=current_question),\n",
    "        ]\n",
    "        rephrase_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        prompt = rephrase_prompt.format()\n",
    "        response = llm.invoke(prompt)\n",
    "        state[\"rephrased_question\"] = response.content.strip()\n",
    "    else:\n",
    "        state[\"rephrased_question\"] = state[\"question\"].content\n",
    "\n",
    "    print(f\"Rephrased question: {state['rephrased_question']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Question classifier\n",
    "def question_classifier(state: AgentState):\n",
    "    print(\"Entering question_classifier\")\n",
    "    system_message = SystemMessage(content=\"\"\"You are a classifier.\n",
    "Check if the question is about one of the following TechZone topics:\n",
    "1. Information about the owner (Priya Sharma)\n",
    "2. Subscription pricing\n",
    "3. Support hours\n",
    "Answer only 'Yes' or 'No'.\"\"\")\n",
    "\n",
    "    human_message = HumanMessage(content=f\"User question: {state['rephrased_question']}\")\n",
    "    grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_llm = llm.with_structured_output(GradeQuestion)\n",
    "    grader_llm = grade_prompt | structured_llm\n",
    "\n",
    "    result = grader_llm.invoke({})\n",
    "    state[\"on_topic\"] = result.score.strip()\n",
    "    print(f\"on_topic = {state['on_topic']}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37af918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router based on topic\n",
    "def on_topic_router(state: AgentState):\n",
    "    return \"retrieve\" if state.get(\"on_topic\", \"\").lower() == \"yes\" else \"off_topic_response\"\n",
    "\n",
    "# Step 3: Retrieve docs\n",
    "def retrieve(state: AgentState):\n",
    "    documents = retriever.invoke(state[\"rephrased_question\"])\n",
    "    state[\"documents\"] = documents\n",
    "    print(f\"Retrieved {len(documents)} documents\")\n",
    "    return state\n",
    "\n",
    "# Document relevance grader schema\n",
    "class GradeDocument(BaseModel):\n",
    "    score: str = Field(description=\"Relevant? 'Yes' or 'No'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c80202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Document relevance check\n",
    "def retrieval_grader(state: AgentState):\n",
    "    system_message = SystemMessage(content=\"Grade if document is relevant to the question. Only 'Yes' or 'No'.\")\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_llm = llm.with_structured_output(GradeDocument)\n",
    "\n",
    "    relevant_docs = []\n",
    "    for doc in state[\"documents\"]:\n",
    "        human_message = HumanMessage(content=f\"User question: {state['rephrased_question']}\\nDoc: {doc.page_content}\")\n",
    "        grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "        grader_llm = grade_prompt | structured_llm\n",
    "        result = grader_llm.invoke({})\n",
    "        if result.score.strip().lower() == \"yes\":\n",
    "            relevant_docs.append(doc)\n",
    "\n",
    "    state[\"documents\"] = relevant_docs\n",
    "    state[\"proceed_to_generate\"] = len(relevant_docs) > 0\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router based on retrieval\n",
    "def proceed_router(state: AgentState):\n",
    "    if state.get(\"proceed_to_generate\", False):\n",
    "        return \"generate_answer\"\n",
    "    elif state.get(\"rephrase_count\", 0) >= 2:\n",
    "        return \"cannot_answer\"\n",
    "    else:\n",
    "        return \"refine_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Refine question if needed\n",
    "def refine_question(state: AgentState):\n",
    "    rephrase_count = state.get(\"rephrase_count\", 0)\n",
    "    system_message = SystemMessage(content=\"Refine the question slightly for better search.\")\n",
    "    human_message = HumanMessage(content=state[\"rephrased_question\"])\n",
    "    refine_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(refine_prompt.format())\n",
    "    state[\"rephrased_question\"] = response.content.strip()\n",
    "    state[\"rephrase_count\"] = rephrase_count + 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Generate answer\n",
    "def generate_answer(state: AgentState):\n",
    "    response = rag_chain.invoke(\n",
    "        {\"history\": state[\"messages\"], \"context\": state[\"documents\"], \"question\": state[\"rephrased_question\"]}\n",
    "    )\n",
    "    state[\"messages\"].append(AIMessage(content=response.content.strip()))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Fallback responses\n",
    "def cannot_answer(state: AgentState):\n",
    "    state[\"messages\"].append(AIMessage(content=\"Sorry, I couldn't find any relevant information.\"))\n",
    "    return state\n",
    "\n",
    "def off_topic_response(state: AgentState):\n",
    "    state[\"messages\"].append(AIMessage(content=\"I can only answer questions about TechZone's owner, pricing, or support hours.\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build workflow\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"question_rewriter\", question_rewriter)\n",
    "workflow.add_node(\"question_classifier\", question_classifier)\n",
    "workflow.add_node(\"off_topic_response\", off_topic_response)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"retrieval_grader\", retrieval_grader)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_node(\"refine_question\", refine_question)\n",
    "workflow.add_node(\"cannot_answer\", cannot_answer)\n",
    "\n",
    "workflow.add_edge(\"question_rewriter\", \"question_classifier\")\n",
    "workflow.add_conditional_edges(\"question_classifier\", on_topic_router, {\n",
    "    \"retrieve\": \"retrieve\",\n",
    "    \"off_topic_response\": \"off_topic_response\",\n",
    "})\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"retrieval_grader\")\n",
    "workflow.add_conditional_edges(\"retrieval_grader\", proceed_router, {\n",
    "    \"generate_answer\": \"generate_answer\",\n",
    "    \"refine_question\": \"refine_question\",\n",
    "    \"cannot_answer\": \"cannot_answer\",\n",
    "})\n",
    "workflow.add_edge(\"refine_question\", \"retrieve\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"cannot_answer\", END)\n",
    "workflow.add_edge(\"off_topic_response\", END)\n",
    "workflow.set_entry_point(\"question_rewriter\")\n",
    "\n",
    "graph = workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example runs\n",
    "print(\"\\n--- Off topic ---\")\n",
    "graph.invoke({\"question\": HumanMessage(content=\"What's the weather today?\")}, config={\"configurable\": {\"thread_id\": 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e674b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- On topic ---\")\n",
    "graph.invoke({\"question\": HumanMessage(content=\"Who is the owner of TechZone?\")}, config={\"configurable\": {\"thread_id\": 2}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
